# 前言

近年来，计算机视觉、机器人技术、机器学习和数据科学一直是推动技术重大进步的一些关键领域。任何人看了以上领域的论文或书籍，都会被一种奇怪的术语所迷惑，这些术语涉及到奇异的术语，如核PCA、岭回归、套索回归、支持向量机（SVM）、拉格朗日乘数、KKT条件等。支持向量机追逐牛来捕捉它们。用某种超级套索？不！但是人们很快就会发现，在一个新领域（也许是为了让局外人远离俱乐部）的行话背后，隐藏着许多来自优化理论的“经典”线性代数和技术。主要的挑战是：为了理解和使用机器学习、计算机视觉等工具，人们需要有扎实的线性代数和优化理论背景。老实说，一些可能性理论和统计数据也应该包括在内，但我们已经有足够的理由去应付了。

许多关于机器学习的书都在与上述问题作斗争。如果不知道拉格朗日对偶框架，如何理解岭回归问题的对偶变量是什么？同样，在不了解拉格朗日框架的情况下，如何讨论支持向量机的对偶公式？

最简单的办法就是把这些困难从地毯下扫除。如果一个人只是我们上面提到的技术的消费者，那么食谱方法可能就足够了。但是这种方法不适用于真正想做认真研究并做出重大贡献的人。要做到这一点，我们相信一个人必须有扎实的线性代数和优化理论的背景。

这是一个问题，因为它意味着投入大量的时间和精力研究这些领域，但我们相信毅力将得到充分的回报。

我们的主要目标是介绍线性代数和优化理论的基本原理，记住机器学习、机器人和计算机视觉的应用。这项工作包括两卷，第一卷是线性代数，第二卷是优化理论和应用，尤其是机器学习。

这第一卷涵盖“经典”线性代数，直到并包括初级分解和约旦形式。除了涵盖标准主题之外，我们还讨论了一些对应用程序很重要的主题。其中包括：

\1.    Haar基和相应的Haar子波。

\2.    阿达玛矩阵。

三


 

\3.    仿射图（见第5.4节）。

\4.    规范和矩阵规范（第8章）。

\5.    赋范向量空间中序列和序列的收敛性。矩阵指数ea及其基本性质（见第8.8节）。

\6.    单位四元数的组su（2），以及单位四元数在so（3）中的旋转表示（第15章）。

\7.    代数与谱图理论导论。

\8.    SVD和伪逆，特别是主成分分析在短主成分分析中的应用（第21章）。

\9.    计算特征值和特征向量的方法，主要集中在QR算法上（第17章）。

四个主题比平常更详细。这些是

\1.    二元性（第10章）。

\2.    双重规范（第13.7节）。

\3.    正交群o（n）和so（n）的几何结构，以及单群u（n）和su（n）的几何结构。

\4.    光谱定理（第16章）。

除了少数例外，我们提供了完整的证据。我们这样做是为了使这本书自给自足，但也因为我们相信，如果不拿出一些证据，就无法获得对这一材料的深入了解。然而，我们的建议是在第一次阅读时跳过一些校样，特别是如果它们是长的和复杂的。

标有符号~的章节或章节包含通常更专业或更高级的材料，第一次（或第二次）阅读时可以省略。

确认：感谢Christine Allen Blanchette、Kostas Danilidis、Carlos Esteves、Spyridon Leonardos、Stephen Phillips、Jo∙Ao Sedoc、Jianbo Shi、Marcelo Siqueira和C.J.Taylor报告错误和提供有用的评论。